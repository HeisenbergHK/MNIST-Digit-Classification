{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI6Q9AWYjUrW"
      },
      "source": [
        "# Exploring Backpropagation and Learning Heuristics in Deep MLPs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Base Model (A nueral network with 3 hidden layer without any additional heuristics)"
      ],
      "metadata": {
        "id": "X8VyO8KgGv6B"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg8_-EVYjW0j"
      },
      "source": [
        "### Importing tensorflow & matplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FiNG29Qgfr6k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWZsql0djdTg"
      },
      "source": [
        "### Setting the parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "go4dr6ucgBqh"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "BATCH_SIZE = 64\n",
        "VERBOSE= 1\n",
        "NB_CLASSES= 10\n",
        "N_HIDDEN= 128\n",
        "VALIDATION_SPLIT= 0.2  #How much of TRAIN in reserved for VALIDATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLFejA-ljgAG"
      },
      "source": [
        "### Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "rN9z16_BgFlD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4f0dd157-905d-4d83-8843-bfcc66689691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = keras.datasets.mnist\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5V_HzhTgy1q"
      },
      "source": [
        "### Visualization of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "02HTOPe6gKoj",
        "outputId": "46987704-6250-4218-8743-a86ea88de822"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x15000 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ4AAACMCAYAAAA9QmNpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv1UlEQVR4nO3de5zMdfv48Wv2wO5iscs6s7S7thYREjlUJHWHhHT6RikhpJRuqtt9K+66O6uUEhJJlEh3J910ss6U09p1WGFZrLO1p9n9/fF79P7MNZq1duezsztez8ejx+O65vrMzDuzn5nZ937e19tRUFBQIAAAAAAAAICXBfh6AAAAAAAAAPBPTDwBAAAAAADAFkw8AQAAAAAAwBZMPAEAAAAAAMAWTDwBAAAAAADAFkw8AQAAAAAAwBZMPAEAAAAAAMAWTDwBAAAAAADAFkw8AQAAAAAAwBZMPAEAAAAAAMAWfj/xlJ2dLU899ZTUrVtXQkNDpV27dvL999/7elgooTNnzsiECROkR48eEhERIQ6HQ2bNmuXrYaGE1q5dKyNGjJCEhASpVKmSNGzYUO644w5JTk729dBQAlu3bpX+/ftLkyZNJCwsTGrUqCGdO3eWL7/80tdDg5dNmjRJHA6HNGvWzNdDQTGtWLFCHA7HX/63atUqXw8PJbRhwwbp1auXRERESFhYmDRr1kymTJni62GhBAYNGuTxnHU4HHLgwAFfDxHFlJKSInfeeafUr19fwsLCJD4+XiZOnCiZmZm+HhpKYP369dKjRw8JDw+XKlWqSPfu3WXTpk2+Hpbtgnw9ALsNGjRIFi5cKKNHj5bY2FiZNWuW3HLLLbJ8+XLp2LGjr4eHYjp69KhMnDhRGjZsKFdeeaWsWLHC10OCF7z44ovy66+/Sv/+/aVFixZy6NAheeutt+Sqq66SVatW8ctsObV37145ffq0DBw4UOrWrSuZmZny2WefSa9evWTatGkyZMgQXw8RXrB//36ZPHmyVKpUyddDgReMGjVK2rZtq26LiYnx0WjgDd9995307NlTWrVqJc8++6xUrlxZdu3aJfv37/f10FACDz/8sHTr1k3dVlBQIEOHDpXo6GipV6+ej0aGkti3b59cffXVUrVqVRkxYoRERERIYmKiTJgwQdavXy+LFy/29RBRDBs2bJCOHTtKgwYNZMKECZKfny9Tp06VLl26yJo1a6Rp06a+HqJtHAUFBQW+HoRd1qxZI+3atZOXXnpJnnjiCRERycrKkmbNmklUVJSsXLnSxyNEcWVnZ8vx48eldu3asm7dOmnbtq3MnDlTBg0a5OuhoQRWrlwpbdq0kQoVKpjbUlJSpHnz5tKvXz+ZM2eOD0cHb3I6ndK6dWvJysqSpKQkXw8HXnDnnXfKkSNHxOl0ytGjR2XLli2+HhKKYcWKFXL99dfLggULpF+/fr4eDrzk1KlTEhcXJx06dJCFCxdKQIDfL3q4pP3yyy/SqVMnmTRpkowfP97Xw0ExTJ48WZ5++mnZsmWLJCQkmNsHDhwos2fPlmPHjkn16tV9OEIUx9/+9jdJTEyUlJQUiYyMFBGRgwcPSlxcnHTv3l0+++wzH4/QPn79qbNw4UIJDAxUf00PCQmRwYMHS2Jiouzbt8+Ho0NJVKxYUWrXru3rYcDLOnTooCadRERiY2MlISFBtm/f7qNRwQ6BgYHSoEEDOXHihK+HAi/46aefZOHChfL666/7eijwotOnT0teXp6vhwEv+PjjjyU9PV0mTZokAQEBcvbsWcnPz/f1sGCTjz/+WBwOh9x9992+HgqK6dSpUyIiUqtWLXV7nTp1JCAg4Lzvyygffv75Z+nWrZuZdBL5/69ply5dZOnSpXLmzBkfjs5efj3xtHHjRomLi5Pw8HB1+9VXXy0ickmspQTKu4KCAklPT5caNWr4eigoobNnz8rRo0dl165d8tprr8nXX38tXbt29fWwUEJOp1NGjhwpDz74oDRv3tzXw4GX3H///RIeHi4hISFy/fXXy7p163w9JJTAsmXLJDw8XA4cOCBNmzaVypUrS3h4uAwbNkyysrJ8PTx4UW5urnz66afSoUMHiY6O9vVwUEzXXXediIgMHjxYNm3aJPv27ZP58+fLO++8I6NGjWJZezmVnZ0toaGh590eFhYmOTk5fn21uF/3eDp48KDUqVPnvNv/vC0tLa20hwTgIs2dO1cOHDggEydO9PVQUEJjxoyRadOmiYhIQECA3H777fLWW2/5eFQoqXfffVf27t0ry5Yt8/VQ4AUVKlSQvn37yi233CI1atSQbdu2ycsvvyydOnWSlStXSqtWrXw9RBRDSkqK5OXlSe/evWXw4MHy73//W1asWCFvvvmmnDhxQubNm+frIcJLvv32W8nIyJB77rnH10NBCfTo0UOee+45mTx5sixZssTc/vTTT8vzzz/vw5GhJJo2bSqrVq0Sp9MpgYGBIiKSk5Mjq1evFhHx680A/Hri6dy5c1KxYsXzbg8JCTF1AGVXUlKSPPLII9K+fXsZOHCgr4eDEho9erT069dP0tLS5NNPPxWn0yk5OTm+HhZKICMjQ/7xj3/Is88+KzVr1vT1cOAFHTp0kA4dOpi8V69e0q9fP2nRooWMGzdOvvnmGx+ODsV15swZyczMlKFDh5pd7G6//XbJycmRadOmycSJEyU2NtbHo4Q3fPzxxxIcHCx33HGHr4eCEoqOjpbOnTtL3759JTIyUr766iuZPHmy1K5dW0aMGOHr4aEYhg8fLsOGDZPBgwfL2LFjJT8/X55//nk5ePCgiPj3/IRfL7ULDQ2V7Ozs827/85Liv7rMDUDZcOjQIfnb3/4mVatWNf3aUL7Fx8dLt27d5L777jPr2Hv27Cl+vMeF33vmmWckIiJCRo4c6euhwEYxMTHSu3dvWb58uTidTl8PB8Xw53feu+66S93+Zw+gxMTEUh8TvO/MmTOyePFiuemmm1QPGZQ/n3zyiQwZMkSmT58uDz30kNx+++3ywQcfyMCBA+Wpp56SjIwMXw8RxTB06FAZP368fPzxx5KQkCDNmzeXXbt2ydixY0VEpHLlyj4eoX38euKpTp06ZvbQ1Z+31a1bt7SHBKAITp48KTfffLOcOHFCvvnmG85VP9WvXz9Zu3atJCcn+3ooKIaUlBR57733ZNSoUZKWliapqamSmpoqWVlZkpubK6mpqXLs2DFfDxNe0qBBA8nJyZGzZ8/6eigohj8/R90bFUdFRYmIyPHjx0t9TPC+L774QjIzM1lm5wemTp0qrVq1kvr166vbe/XqJZmZmbJx40YfjQwlNWnSJElPT5eff/5Zfv/9d1m7dq3Z7CEuLs7Ho7OPX088tWzZUpKTk82uAH/6cw1ly5YtfTAqAIXJysqSnj17SnJysixdulSuuOIKXw8JNvnzcuKTJ0/6eCQojgMHDkh+fr6MGjVKGjdubP5bvXq1JCcnS+PGjenN5kd2794tISEhfv3XWH/WunVrETm/f8if/U5ZKusf5s6dK5UrV5ZevXr5eigoofT09L+8wjQ3N1dEhB1Hy7nq1atLx44dzaYsy5Ytk/r160t8fLyPR2Yfv5546tevnzidTnnvvffMbdnZ2TJz5kxp166dNGjQwIejA+DO6XTKgAEDJDExURYsWCDt27f39ZDgBYcPHz7vttzcXJk9e7aEhoYyuVhONWvWTBYtWnTefwkJCdKwYUNZtGiRDB482NfDxEU6cuTIebf99ttvsmTJEunevbsEBPj1V0e/9We/nw8++EDdPn36dAkKCjI7aKH8OnLkiCxbtkz69OkjYWFhvh4OSiguLk42btx43lXh8+bNk4CAAGnRooWPRgZvmz9/vqxdu1ZGjx7t15+xft1cvF27dtK/f38ZN26cHD58WGJiYuTDDz+U1NTU8z54Uf689dZbcuLECfPXui+//FL2798vIiIjR46UqlWr+nJ4KIYxY8bIkiVLpGfPnnLs2DGZM2eOqt97770+GhlK4uGHH5ZTp05J586dpV69enLo0CGZO3euJCUlySuvvMIVFOVUjRo15Lbbbjvv9tdff11E5C9rKPsGDBggoaGh0qFDB4mKipJt27bJe++9J2FhYfLCCy/4engoplatWskDDzwgM2bMkLy8POnSpYusWLFCFixYIOPGjWNJux+YP3++5OXlsczOTzz55JPy9ddfS6dOnWTEiBESGRkpS5cula+//loefPBBztly6qeffpKJEydK9+7dJTIyUlatWiUzZ86UHj16yKOPPurr4dnKUeDnXV2zsrLk2WeflTlz5sjx48elRYsW8txzz8lNN93k66GhhKKjo2Xv3r1/WduzZ49ER0eX7oBQYtddd538+OOPHut+/nbltz755BP54IMPZPPmzZKRkSFVqlSR1q1by8iRI1kO4Ieuu+46OXr0qGzZssXXQ0ExTJkyRebOnSs7d+6UU6dOSc2aNaVr164yYcIEiYmJ8fXwUAK5ubkyefJkmTlzpqSlpUmjRo3kkUcekdGjR/t6aPCC9u3by+7duyUtLY0NWfzEmjVr5J///Kds3LhRMjIypHHjxjJw4EAZO3asBAX59fUjfmvXrl0yfPhw2bBhg5w+fdq8po8//rhUqFDB18Ozld9PPAEAAAAAAMA3/HcRIQAAAAAAAHyKiScAAAAAAADYgoknAAAAAAAA2IKJJwAAAAAAANiCiScAAAAAAADYgoknAAAAAAAA2CKoqAfeGNDfznHgInyfv8Brj8XrWnbwuvonb76uIry2ZQnnrH/idfVPvK7+ic9Y/8U56594Xf1TUV5XrngCAAAAAACALZh4AgAAAAAAgC2YeAIAAAAAAIAtmHgCAAAAAACALZh4AgAAAAAAgC2YeAIAAAAAAIAtgnw9AAAAAABlh6N1gokfmLdU1UIcuSZ+Ozau1MYEACi/uOIJAAAAAAAAtmDiCQAAAAAAALZg4gkAAAAAAAC2oMcTAAAAcAlL+fAqlX/SeZqJr6ygj+2xrZ+JK8heW8cFAPAPXPEEAAAAAAAAWzDxBAAAAAAAAFtc0kvt8m5orfKDw7NN/Fv7D1XtysSBJq77tr7mOHD5BhtGBwAAAHhHUHRDEzdekK5qS+u+r/J8l/iVjGaqFjYo18R53hseAMCPccUTAAAAAAAAbMHEEwAAAAAAAGzBxBMAAAAAAABscUn1eMrv0krlU2a8pfKYYOufI1+0je1nmnhHG6eqPRl9jXcGiFK366X2Jt5+t/55CHYEmrjz8CGqFvrFGnsHhvMERkao3FE13MR/9K2ralk1Ckwc86/fVC0/M9OG0UFExNE6wcT5FfTHy4HrKpl468ipqpZboN9Ti6vrFmuL70q9D6paflaWV54Dpe9sv3YmfvE/76jac3fcZ+KCdVtKbUz+xhGkz9fAmjWKfN8dT0Sb2Bmmvz01uuywicOGO1Tt0KtWv8wNbear2lHnWRO3WzBG1WIeX1XksV3qXN+TRURy/nPKxK/U/cXtaP236BazRpk4ar1+XcMOrPbOAAGUusBqVVXecvlxE3cN36pqr/Syvlc5t+6wd2Dwe1zxBAAAAAAAAFsw8QQAAAAAAABb+P1Su9zubUw8dupHqhYXXEHl+S4L7Hbn5qrayfyKJm5VUZUk++a2Jg5dvlk/Jss7ypRDj3VQ+YoB/zFxbkEF98MtBZ5L8J6AZvEmThkXqmoPNF+p8jGR3xbpMS+vNVTlsYPWF3N0EBEpaH+liVMG6XPmtRvmmTjYoTfZ7hZ62sS5BfpvHvnnLW4unu+bfWrilh89oGqNh6WZ2Hk0wyvPVxac6321ziOtJcIRMxJLezi2ONzG+nl5LrWnD0dS9gVeHqvygorBJk7rUk3Vzl1jLWeLqHpW1X6+Ui99K66vM6uY+MW3eqja6uYfm3hP7jlVeyH9RhPX/ZkP4OLKigpT+bfxs4p837AD1tLIsM9ZWgeUNYExjVWeW6eax2ODj54x8YGbaqral1FWq5H3TzbQdzx0pPgDBNxwxRMAAAAAAABswcQTAAAAAAAAbMHEEwAAAAAAAGzhFz2eAsOtbdXPdo5Xtcdes3oIXB96RjTP826zjuteQD9MbW/iX/85RdW+n/6uia+YM0LVmjzlHz02/MWZBrqXTERAIX2dYAtH2+Ym3vlYoKqt6GitM68ZqJupBbidr19lVjfx7uwoVXukurXl60ed31e159oONHHBWt2TDRdW8PwxEyfFf+7DkRRuU4cZKr+p3XATV/zKf3o8pXXW50XYZSesRP8TlB8B+n2hoKHV/6drVJKq/eDQn9WXIud1V5n41Vlvq5p7L0u75RY4Vf6PNweZOOis7tXUfoH1fanKAd0TruJR6zUPW0d/oYvhaJ1g4uFvfKpq7p+jrq59Wn9/jZq10sORKG9Sn2uv8nyr9ZuEND2pahuu1v1wXb17oomJlyZU93gcLk7BtS1NnDpCv082q5cmntxT+weV96p03OOxTRdZ34EaxunHDHRY7wsrjjdVNUdIiMfHRNHl3NRG5XvvsX4fHXbVj6o2unqyx8dpPn2kysMOWj8vJzpkq1qjudbrWuHbdUUfrI244gkAAAAAAAC2YOIJAAAAAAAAtvCLpXb7Z9cz8dq2bxdyZNFNjFqr8m8qW5fz35/aXdU+jF5m4vAr/GcJh78407+diT/r84Zb1dou+N0TepnmsjusyyIr7d2qat7Z/N1/Bda0tmpNfqOeqn3ZYaqJmwQHi1ZRPJl5Sm/x+kXfjibOr6gf55Gl1lK7NhX10o9ztUJNzAXEF+/ACpfXId7zcYlZ+rV84L8PWYnD7eBCdku/5ip9yfHM6O8uMMJLy79uXaDyF7d393Bk+RF4WSOVJ3Wx1gy2XHOvqtVluaxU3GEtm1ifpd8n44LTS/z4Yw5eo/LdZ2qofNZlC018Ml+fzLWmFG+5ViFvCbiA5IGVTdy70lFVuzWpj4kDh+plmNVTaA1Rnpy77WqVH02wfqULv/awqm1sob/7BjrcP4QthX2/vb+q9d0qYFusqi25IrKQe6Iw+7qGmXhr5zeLfL/j+Vkqb7V6iIlfbaGX2e7oM1U8cRZYPw9Jn+gvdrUOsOS2uI4MtZa4vjlWz0+4/m7ivgR6YGo3lbeq+oeJf3vQ/fdYi/vjdIi4y8QR3xZhwKWAK54AAAAAAABgCyaeAAAAAAAAYAsmngAAAAAAAGCLctnjKe+G1iqf19Lagj1APG8dfP/eripft+xylW8ebD3O8nO6+0vUOmtr353H9frX4MnLref3vGwapSTrVr3ufcK/rf4gccGeX6AP3++h8trbWNdcXAfutdb+b+3ivh7Zva/TX5vj3tPpNr1tunOH1fvH0SpBUDoavmBtydrn07s8HufIyVV57J7ibYl+oobuG7FsVRUTdws97fF+N2weoPLw5VafNn/q0RbsyLvwQeVM0PRMj7Vzu8JLcSTlQ97BQyZ+88X+qjapx1kTB/5eWdV+G+65l8jzR1uYeGe3MFVznjio8rvbW9t0p47Sj9NYfvP4HPCOpuv0Z+pHtV418cIzDVXN8URVEztTdO9K+EZQk2iVR31s9YrtV2OteBIf/IvK6wdZfRXde708c1h/L3bvY1tUwY5AEzcIdu9pS4+notr5mu6b90vf/7hkoarWYuUgE2dl6NoVk9JUXm+fdU6/1EX3QwyfOd3Erd3aqa7Ntrrq1Zmh37P96fuSHRzB1rxDVrcrVe2zcS+ZuG6Q/kcfvPdGE+99uamqVfpqk8qXh1nv4z8uitPPEbvE49hObbLOyQiPR5UurngCAAAAAACALZh4AgAAAAAAgC3KzVK7/C6tTDxlxluqFhNs/W/ku10U2Mt169h+Z1Wt2t/0hr1XfDTCxHFv71O1gH0bTVz9Zz223EnWloiftZihag9cb113Hrh8g8B+B+/V24teH+qaB6qa65aVtd9gaZ231OuVWqTjFp6prfJXk63lsLXG6vPTuSPF4+Mcb87ym9JSkJtjYueOnbY/X/rt+rLi5hUWu2Ru14u7SEvTFxZXztztzWH5VH7HlibuFPKL5wPLqehK7ks4LA2WOT3WIBIxM1HlNb+0LrV3ZhxTtYRmD5h4a2f93WXJe11MHHWi8M9GR6K1NKNxYiEHwmuOD7K26X6ljv5OnO/ScuKZH/qq2uVnrXOLM8l3zvRvZ+LHJ81TtVsLef/TPH/+9ew9UOWBB/W537vO/SY+27CSqo15ca6Jbw477vE5pqd1drvl0F8eh/Plh+mzLyrQWs78xdlqqtbkKaulQN7uzarmvtA+oOUVJj75lG5F0Lai1WrkoFMvZx88fayJ65/ld6GLcXBEGxOvecK9tYh1jvbf2VNV8vpa7SjCjupWFPq3H5G0IVaLodWx7s9h+TqzispjpllzGWWlKQNXPAEAAAAAAMAWTDwBAAAAAADAFkw8AQAAAAAAwBZltseTo7XeHv3o4+dMHOeydaGIyPpsK/7fmStULeMTa0v2yOO6+UDVOat07hIXdy1krUC95jpjtLWONmp5MR8UhQqqX0/lWzvNVHlugbWWerve4V3+eNXqH1NJirfdO/7CQ9Z5cMUjI1WpwffW61Fpq+4JUGNvsokvpv9EZi3HhQ9CuXFkmNW/JP7eJFVzf4/15PKxe1TuT/1M9t5qbans2huiPAuKtrYL7hfheXvg0D2654g/va52cB713C8m91QFj7WEe7aZ+Mg7ujei5POvXtoCa0Wp/EiHon1LDT6hXztn8q5iPf8fEzqoPKterocjReKGrC3Wc1xK6oyyXoei93QSOea0fuHp+t5YVau9yqoFr1uvauf9tBxIM2Ha6FaqVFhfJ9e+nM57Aj0eh8JFf667+LzZsYmJH6mmz9EJL1s9uBo+UFXVpIbuZZn7itXX6ef4L1Rtc471U3DnbP2z02gyfZ2KKuXNdirfcfubJs53O/by74eaOP6JVFUr7LPZ3dBhiy98kIg8P0n3dqu+r+w1XeSKJwAAAAAAANiCiScAAAAAAADYokwttQsIs5YM5P3nlKqtiv/cxHvyclTt8fFjTFz95z9ULarSYRP74uLwq+vsNXGqD57fXwUmNDVxm4+3FPl+Az4fpfLLPlvl4UiUhHOntcwp5rE9Ho/z1vaeuW1PX/gglBmHR+hlGwOH/Vfl94a/bOIqAZ6XA7l77shVJi7IzinkyPItKMbzz3tWUrXSG4gX7XvdWk5wbUV9wfoHp+pbyQn93QDFd/lT1tLm+5t3VbWZjX4wcZf+j6halfl8bpa6PP1p2an5DhMHO/SSp1yXVTz1fir6p+zeie31DQXWEvaJd81VpT6Vjnl8nOA0azy3dLld1Zwpu4s8Hn9yesA1Kn+34csumefl44vP1lD51MfuMHGDr7yzPKpJnaNFPvaZn6zXM24/SyqLK+TnbSqfurmziR/ppJfavdriUxM/3edBVfv7OH1e9qrkeZnk3TMeM3Gj51hadzF2vWKdvztuf1vVTuZnmbh/0t2q1nSkS/uQ056/twVUqqTyjH4tVN678kvWsRKqavELrM/nmFllb2mdO654AgAAAAAAgC2YeAIAAAAAAIAtmHgCAAAAAACALcpUj6dzXRJM/G38VI/HPfjoYyqv8oXVb8BbPWNQtu3tFWnihZEb3aq638Hdu3qaOO4FvXaaTaHLlj/+YfX+yQvT282Kw+1gl/LtsZ7XNY/Yf53KQ7/Z8FcPgSJy7a+WfH91VevSsWj91pY2eFPl+edtQuu5r9POXOtdfsA7Y1St4aJ06zFPF2/b8PIuap37v6XvBNaIVHl63zgTR9yxX9V+jPvAJQtRtXfevs3EUen0pvAW54mTJs4Ydrmq/bHknIn//vxsVRt3Rx+VF2y0tvhuMMntvbiAd1lvyLilqcoXNZxi4twC/TfkJWet9+WK6Zmq5vpq5HdppWpR7Q6p/Ptmn4on+/OyTfzfs/pnZ0jVVBPHfaL7rib/n/Ue4NyWLJeK2o/oz6O6QZ77Orl+Z9n+UjNVq/TV6mI9f1DtWipP63uZiefHvOR2tPX56/79qd63XK/gDfmZ+rzMPe355+H6UKuH0Mrn31K1ALcvxq6f/gk/PaBqMZ/6tudxeRJYK0rlH/ax5iTcv6+69nWqcONeVSvs21hAyytM3GzGdlV7vtYUt6Otn49rN92pKk3/ad23PLyuvIMAAAAAAADAFkw8AQAAAAAAwBZlaqldi+c2mTjAbU7s/r3WVr+hX6wprSEVietWtrluV5UHOrjM3BuO3a+3+V001PXS4GBVG7qvi8pzB1qXKDqP6Mu+Yb/A8HCVZ10da+Lgcemq9nu8XoLl6vwtoz1fVLr8XJiJ9w9pqGoFedvdD0chCq5tqfJBMxeZuHelom/DrBX/bx6jdg4wcb0X9bKr8nCZsd3ORVj/tpUKOc5dfidr2U1BoL58f1836z00p26uqgVUsP7Vv+ukz99gt+Wxh5zW4zy7Wy/XOpZvXZQeFqBfyVqrrW2I+US1R/5v+n3xzn89aeK5E15WtU3X6KV34rJTfEKlEaoU+/5BE+ftTi3ZIC8xgZERJj4d7b7W3LL8nF6a+uTX1tKP2I2rVM3R2mppcfTxc6q2ptlCla/Ptt5LHv79XlWr+bq1pXdONf2rxJC337GeP1R/xidLk/P/By4Bf8yOUfnkkS1NvOtsTVU7fo+1dLXSnuItrXOXPFr/u2/5vzdcMr20/fVj1hKgtDtrqJq3xgMtZF/whQ8qgluTepu4ycu6+Yxzx06vPMelwBGilz62qej522XoKOv8cTRqoGopQ+ubuHu3Dar2WNR7Jm4YFKpq7kv0nC5L1h3z9TnpPJHicWxlEVc8AQAAAAAAwBZMPAEAAAAAAMAWTDwBAAAAAADAFj7t8XTi/3TfnmdqWX0E8t3WHK//zlpz3FDK1nbKrr1m3LdZ/Ga7Ne5Y0es7UTjXbdvdtxB1327bVeL+aJU3SC3aFu8oPkdFvR46p0tzEz829SNVuz70BxOnO7NVbfk5axvofyT3VrV5CbNUXth2xCEBVh+a3XdUU7UmO6yfnfysLMHFCXTpsuPei6+ozu/XVfT7fnO51WOq0z2PqFrVuavcD/dL2VlWP4h8t65HM8e/ZuIlI1oW+TGfipxuYvctms8V5Jg4zal7Hbx15DoTd1s2WtWqbdSf43W+s/q9OPbuV7Uj260eB7UCdR+pgrWbCxk57BAxI9HEI3bo8yz8Bf3azWvyrYm33qc/q+MbPGjipv/S7xfOlN0lHqc/O35TnIk3Dn3D43HDFw9WeewY630wKFr3OMz5zykTr4r/XNX25OWo/O5fRpq46dAkVXO2tHo13j35W1Xbk2d9rr6y7kY9tm2X5vfgyOmJKl813bWnzwm3o93zi3fiPv37VeI9L7sdYb03Z+br99vZ86zXrP6esvX7lr9wBOlfv6u1tz4b3T9/C3NLUi99Q1frvblA9guKpyBL/26yOts6X9tV1OfL4mWfmNh9DqAwy85ZvZpS3L4EXx96RuXrcqzztdps/V5S3nDFEwAAAAAAAGzBxBMAAAAAAABswcQTAAAAAAAAbOHTHk95oTqvGmCtYUzM0v1bmsxOs+5n66j+WkBYmImTXm7mVl1vont236wq8Y/uMbHujIELSR5v/Zu79tG6kIYv6Pwi2sfgIgSEWL2SMga0UrWfJ0/xeL+EeVbfiPrL9eta8au1Jo6so9c4z/u2tcrHRHru3eW6Bvv3QXos7feNMnGt2b+pWn5mpsfHvFQ5ft2k8g9u62Hivw+KVLWG31o9QgLPFf+dOmWwtZ4+qcc7xX4cfxVz70YTJ/x7hKo1aHugWI+5/LDVT+bI1/VVLXKrdT5V+GataFYtTtYV+hyuZ/uBpzqoWtuKVt+CT87Uu8BoUZrc3wMy+0WpvO0A6z199VO6F1HS9VbvsHuiu6vayY5eGqCfymhetF4vl43x3Nuu8YJ0lb9S9xePxz746GMqj/1ijYnP3dxW1b6dPtXj48R/NdrEcUPc3y9QGn75t+615t4311Wnt55Qef0X6etkt5NfNlL5Ty0+NXHRuwSJ5Lv1g+JqEu9wph9W+YRhVq/Cl9/V730tXE6tOacaqNrzP1o9uOJm6Z6yQeknTRw175iqXd/gfyofuNx6/gt9zyrr+BkFAAAAAACALZh4AgAAAAAAgC18utSuMBnOyirP251aqs/vurRORGTHC9b28Em99SWsX2dWNXHa2zGqVuX4pbG9tzfkd9HLtZ5v80WR7nfjljtVXnmd5yVYKD5HRb38NenVFlbc2/PSut47blN53EvWFtrul7MGNbCW+Fy55A9VezJym8pP5lvLutp9NkbV6sRbj/tD8/mqlvisNdYBd92qakenWOd5SIbeMtVV4IpLc0toERHntmQTNxlrz3NcnlLTSnp4Pg4ijcd5f2vdOvLHhQ8qobDORzzWnlneV+VxssbDkfAF9/ftWlOsPGusXmIb5rDWIbwfvVTVbu0z2jpu0WovjtA/5Fa1FqcGuP2duOuWfiYOlT2q5vpdqk/EbFVzfZwW749UtYZf6CVWjtYJJh7+xqeqVtjjxP2TpVq+kPJ2OxMHOzapWm4hPSfq/3BK5bSn8I7AmMYqTxlS28RJLd5WNdfldRMO69+FPktuaeItHWeqWotqemk9v/3Yo8K31vK28Y2vLvL9Cvvucrq39ThfNVysarkF+v0+NNXzUtnyhiueAAAAAAAAYAsmngAAAAAAAGALJp4AAAAAAABgizLb4+mJX/urPE7W2/6cruviDz9+TtW2t7H6OnXdPEDVKvWwetZUEXo6FdekWe+pvFmw55XmTxzsbOKqdx1XNaf7wSg2R5D1FrHj9StVLamXtUZ9f162qvWaZjX/iZ6xS9XyXPqD5HZrrWrNXrS2iZ8Qpc/5maf09rMfPd3TxDGf6/MusEakia+7UfefODvA2sJ0Uav3Va3+FN3HytXSs9ZjvhfXxONxKLn022MufBD8VqPFdBkpS/I7tlT5rv4hKm/WMtXErj2d3L15TPcuCVtcvreFLk35bpus5xc4PByp5Rbor/n54rKld8JpVRu1M0nlNQPXmnjBcd3XZNbfupq48dHtqsZ3sNIREOJ2Hjbba+LcAv0quP/8tJr6qIkbbKC/mh3Sbqmj8m33vOmS6fP3io9GmDj2pR2qFnqPS8/jjvo5/rs7QeUNZfPFDxQ+kRdqXftzofO18Syr76buolj+cMUTAAAAAAAAbMHEEwAAAAAAAGzh26V2blcKu27P+kbHear2tsR5/en3Tmyv8s/ue9XEccH6cvGr1gw0cd0+elt3eEerCnoe1P3SQ1eJM68ycdRxtu61y74nrcvrk3q9oWppLsvr+r/wpKpFf2EtPz12g95StuDeKiZe2Ew/Zs1Aa6lbwiduWzS/d1TlYTs8Xx7uPJph4vB5GaoW7vLW0m/4WFWr1W+veDSmmkuy1fNx5ZCjol5ieKK/tSSm+mL9/5p/Wi/P8IaDYzqofPGo/7hknpc/AvAOR5tmKk8eZX0Hev/aD1Wtc0hOkR83uyDXxKuO6c8CyT94ESO89DT60mXJaW9d+6H5fBPfdPNwVTvSMtjETYKPuT2q9bpu6jBDVQLc/ha9PtvKf36lnapVTaGthC8Ehoeb+I9h+pxdH+P6fUq/lm3X3qfy6Ok7TezMZ3Gkt2T2sc6TeY+/7Fa1vst0+PsjqhLz+e9WEl1f1R4f/qnH58v9o9LFDxJlQpVPXN5DX/HdOEobVzwBAAAAAADAFkw8AQAAAAAAwBZMPAEAAAAAAMAWvu3x5LZjsuv2gV1CdV+W0bOsbdcvm6m3GQw+ZPUcSe9SU9UiBuw38ciGP6jazWF6u/YlZ2uZ+L7NPVStxjTW0dph30JrjXqwY1OR71dnhdXvh9Xp9nnnoakeayEuPdp6Dv1J1eqNOm7igeFfFvIMun9PwsejTBwzbq2qOfO8v4lo1FTdH6zA8/+uiBzw+vP7UlZPq39X1Sf+ULUfY6xtf/usvUvfcUfxejwF1alt4gP9mqja/JG6F0LdIM99ndKdVm+x4HMFHo9D+RLosP4OdjwuWNVqf13ao/FPQY0bqXzX/XVN/M8Bn6ha38q6p15RjU9vo/If37jGxNU/TCzWY16qArOt77quPRVF9Hvk99PfVTW9FbfuV1qYPXlZKr/7F6vPYuxcejr5QmBkhMqPfFjDxOtbveF+uNFimu6R2fB53ROTvk72ONDViuOCQ1Tt/j+uM3G1j/R7YYFLn829fSJVLb6i1QsvQAJVrWIG14+UV6fvvMYlW+/xOH/DTywAAAAAAABswcQTAAAAAAAAbOHbpXaFCHHooW2/0bqU+JdO+vLFlGxrCcf9VVOL/ByPpnVS+TcrW5o49lEuK7ZDfpdWKn+95RwT5xboS39P5luXfbf9erSqxe/d5v3B4Tw/nYk3cbuKm1UtItC6NHh8jU0eH+PWpNtV/keitVVsk4UnVS1mq3W5aYENS+tguWnSjyYeE7nF43FJ48P1DWfa/fWBF3BnB+vS8i+ivlK1fAl2P9wYmHqTynfObGriyM9ZuuMvnAUuy4P4k1ixBUU3VPnJ1nVMPGDiN6o2tNrnxXqOMQevUXniVGt5XcSsNapWPZ9ztLiC/md9Ht719BOq1mTYDhN/GL2syI955a8PmNixrYqq1dykP3Njv9CvJUqf87J6Kv+l1QyPx8451cDEDSeu9HgcbOSy+j/frZ9MfoH1weaoqNsJHBl4lYl/G/amqm3NsT4bL//pQVVrPJnXubw62eTS/KJzaf5fAwAAAAAAwHZMPAEAAAAAAMAWTDwBAAAAAADAFj7t8VRrxWGVP/VwexO/WNtzX4DOITkq7xiS6vHYjdnW3NpdPw5Rtbj79faFsUJfJ7tlReitfTuGnHXJ9Dah32ZavSrihqxVtXxBaVh5vbXddrt7blC1k1da52HQEd2jJ+7dA1btkD7Po7P2mZjXsezb3m2aDY+q/+aRmKX7HTy0+j4TxzyUomqRZ+kZ4+8y22b6eghlWlCd2io/NqOSiYc1/lHV7qqSXqznGHGgo4k3vNNS1Wos1D3hIk5zTtqt6hz9/TTDao8pt0rrIj9OI9l84YPgU462zU28+3GHx+Omn2yi8q/6tXfJkr09LBRBYGS2x1ry8ZomTvjxkKp92eAtj/d7eMJoEzeezXutv6j3o/U9J3iE/v03t8D9aP/BFU8AAAAAAACwBRNPAAAAAAAAsIVPl9o5k3epPKV/tImvGDlS1bbdobeX9CT+v8NV3nSqdSlb3Mb17ocDKIQz45iJa03R27bWKuR+eYXUUDb8b9S1Jp49/GpV++1az1s2F5Xr1s4iIgdzq5l4xoZrVS3mfafKm/y6ycQsx7w0BDr4O5irnJva6Pwx6714fMx/Va176FkpjnTnORN3XjJG1eKfSTJxxAm9vINzErBP+jO5Jt7c5iOPx02d01Pl9bet9HAkSktQcpiVdNG1X1t+YuIA0UsoN+dY35r7Ln5U1eIWWUubee/1Hw6X77mzTkWp2l1VDqg8M6GOiSvs22/ruOzGNz0AAAAAAADYgoknAAAAAAAA2IKJJwAAAAAAANjCpz2e3OXtTjVxzGOpqtbrsbZFeow4WatyP96RsFwK36S3EB25/wYTv9vgR/fDAdgkcMUGEzdeE6ZqrUdZPQY+fPh1VWtWwepNcMPmAap2coW1zXuj+XqNet6evSaOFfrtXeqyl9VUubMl3Stcpd6m/y6Y3HxBke739onLVP7Gj91N7HDqviLxz+8xcWz6alXTXdcA2KWg/ZUqj6qc4fHYK5YPMXHsd6f043h3WCiGJu9avYsTKoxQtWX3vmTiZw7comprvmtm4pgJulcXn4z+77Vp/VR+1xNvqLzOsztNnHGihb7zqt9tG5cduOIJAAAAAAAAtmDiCQAAAAAAALYoU0vt4P9cl9uIiOy/xopvldalPBoAIiL5mZkqr/eCdan3+Beu9ni/yrLbY57nfjDgovZrejnBLa9dZeImsqmUR1P2xA1bo/JbhxXv8zFO1nissZwO8L2UgRVVnhS/yMSLzuht1mNfzzVxwbot9g4MFy3vULqJG49PV7WHxnd0yfQyyUaiPw9xaan30Q6VD7jtVpXPj1lq4i7/uEvVIu6uamLniZM2jM67uOIJAAAAAAAAtmDiCQAAAAAAALZg4gkAAAAAAAC2oMcTAAAAAJSyessc+oaeVvjqv+9UperrEkthRABKk/Nohspz+kaq/PJXHjbx9m7TVK1X/GArWfW79wfnZVzxBAAAAAAAAFsw8QQAAAAAAABbsNQOAAAAAEpZpYWrVd5rYVsTVxeW1gGXGveld7EDrbyXtHU7uuwvr3PFFU8AAAAAAACwBRNPAAAAAAAAsAUTTwAAAAAAALCFo6CgoMDXgwAAAAAAAID/4YonAAAAAAAA2IKJJwAAAAAAANiCiScAAAAAAADYgoknAAAAAAAA2IKJJwAAAAAAANiCiScAAAAAAADYgoknAAAAAAAA2IKJJwAAAAAAANiCiScAAAAAAADY4v8BCSi3C/3HPCgAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "f, ax = plt.subplots(1, NB_CLASSES, figsize=(15, 150))\n",
        "\n",
        "for i in range(NB_CLASSES):\n",
        "  sample = X_train[y_train == i][0]\n",
        "  # print(sample.shape)\n",
        "  ax[i].imshow(sample)\n",
        "  ax[i].set_title(i)\n",
        "  ax[i].axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WiEX_C6VjxL4"
      },
      "source": [
        "### Essential Normlizarino (Converting the matrix to an array + One hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GuY1v0kOixmz"
      },
      "outputs": [],
      "source": [
        "RESHAPED = 28*28\n",
        "X_train = X_train.reshape(60000, RESHAPED).astype(\"float32\")\n",
        "X_test = X_test.reshape(10000, RESHAPED).astype(\"float32\")\n",
        "\n",
        "# Normalizing the input between 0 and 1\n",
        "X_train /= 255.0\n",
        "X_test /= 255.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "oelAuMgqjvag"
      },
      "outputs": [],
      "source": [
        "y_train = keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NB_CLASSES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0lr1PScmt1z"
      },
      "source": [
        "### Building the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GEOF-OUdkQ8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "217bb13d-5f46-474c-bb0f-50c3176bd0cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "base_model = tf.keras.models.Sequential()\n",
        "\n",
        "base_model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED, ), activation=\"relu\", name=\"Dense_Layer_1\"))\n",
        "base_model.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", name=\"Dense_Layer_2\"))\n",
        "base_model.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", name=\"Dense_Layer_3\"))\n",
        "base_model.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", name=\"Output_Layer\"))\n",
        "\n",
        "base_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "7Yj4Q6hDFZQj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "gks5Xt03m0tN"
      },
      "outputs": [],
      "source": [
        "base_model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "TmfuwHSCFbdG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nXWJ-icMFSLp",
        "outputId": "f19f71d1-0bc6-4e6d-edfe-c138dbd92b9c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.4939 - loss: 1.7238 - val_accuracy: 0.8811 - val_loss: 0.4545\n",
            "Epoch 2/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.4320 - val_accuracy: 0.9091 - val_loss: 0.3186\n",
            "Epoch 3/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9044 - loss: 0.3290 - val_accuracy: 0.9226 - val_loss: 0.2687\n",
            "Epoch 4/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2844 - val_accuracy: 0.9303 - val_loss: 0.2411\n",
            "Epoch 5/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.2553 - val_accuracy: 0.9358 - val_loss: 0.2222\n",
            "Epoch 6/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.2261 - val_accuracy: 0.9417 - val_loss: 0.2050\n",
            "Epoch 7/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9405 - loss: 0.2040 - val_accuracy: 0.9467 - val_loss: 0.1902\n",
            "Epoch 8/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9436 - loss: 0.1923 - val_accuracy: 0.9500 - val_loss: 0.1765\n",
            "Epoch 9/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9509 - loss: 0.1730 - val_accuracy: 0.9520 - val_loss: 0.1715\n",
            "Epoch 10/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9539 - loss: 0.1601 - val_accuracy: 0.9544 - val_loss: 0.1616\n",
            "Epoch 11/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9571 - loss: 0.1509 - val_accuracy: 0.9567 - val_loss: 0.1547\n",
            "Epoch 12/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9600 - loss: 0.1376 - val_accuracy: 0.9586 - val_loss: 0.1465\n",
            "Epoch 13/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1328 - val_accuracy: 0.9596 - val_loss: 0.1408\n",
            "Epoch 14/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9648 - loss: 0.1231 - val_accuracy: 0.9631 - val_loss: 0.1326\n",
            "Epoch 15/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9671 - loss: 0.1164 - val_accuracy: 0.9634 - val_loss: 0.1321\n",
            "Epoch 16/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1121 - val_accuracy: 0.9636 - val_loss: 0.1271\n",
            "Epoch 17/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9692 - loss: 0.1103 - val_accuracy: 0.9647 - val_loss: 0.1212\n",
            "Epoch 18/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9711 - loss: 0.1018 - val_accuracy: 0.9668 - val_loss: 0.1184\n",
            "Epoch 19/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9724 - loss: 0.0971 - val_accuracy: 0.9663 - val_loss: 0.1170\n",
            "Epoch 20/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9756 - loss: 0.0889 - val_accuracy: 0.9662 - val_loss: 0.1216\n",
            "Epoch 21/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9770 - loss: 0.0827 - val_accuracy: 0.9682 - val_loss: 0.1133\n",
            "Epoch 22/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9772 - loss: 0.0824 - val_accuracy: 0.9686 - val_loss: 0.1100\n",
            "Epoch 23/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9785 - loss: 0.0771 - val_accuracy: 0.9695 - val_loss: 0.1089\n",
            "Epoch 24/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9792 - loss: 0.0737 - val_accuracy: 0.9699 - val_loss: 0.1061\n",
            "Epoch 25/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9795 - loss: 0.0749 - val_accuracy: 0.9688 - val_loss: 0.1063\n",
            "Epoch 26/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 0.0681 - val_accuracy: 0.9696 - val_loss: 0.1048\n",
            "Epoch 27/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9829 - loss: 0.0650 - val_accuracy: 0.9695 - val_loss: 0.1044\n",
            "Epoch 28/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9830 - loss: 0.0634 - val_accuracy: 0.9701 - val_loss: 0.1016\n",
            "Epoch 29/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9835 - loss: 0.0594 - val_accuracy: 0.9721 - val_loss: 0.0995\n",
            "Epoch 30/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 0.0547 - val_accuracy: 0.9704 - val_loss: 0.1010\n",
            "Epoch 31/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0527 - val_accuracy: 0.9713 - val_loss: 0.0986\n",
            "Epoch 32/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9849 - loss: 0.0532 - val_accuracy: 0.9718 - val_loss: 0.0994\n",
            "Epoch 33/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0508 - val_accuracy: 0.9697 - val_loss: 0.1011\n",
            "Epoch 34/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0496 - val_accuracy: 0.9719 - val_loss: 0.0973\n",
            "Epoch 35/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9879 - loss: 0.0464 - val_accuracy: 0.9722 - val_loss: 0.0966\n",
            "Epoch 36/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9878 - loss: 0.0448 - val_accuracy: 0.9728 - val_loss: 0.0958\n",
            "Epoch 37/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9892 - loss: 0.0402 - val_accuracy: 0.9719 - val_loss: 0.0980\n",
            "Epoch 38/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9897 - loss: 0.0396 - val_accuracy: 0.9728 - val_loss: 0.0952\n",
            "Epoch 39/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0370 - val_accuracy: 0.9728 - val_loss: 0.0965\n",
            "Epoch 40/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 0.0390 - val_accuracy: 0.9727 - val_loss: 0.0961\n",
            "Epoch 41/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0351 - val_accuracy: 0.9742 - val_loss: 0.0931\n",
            "Epoch 42/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0323 - val_accuracy: 0.9730 - val_loss: 0.0962\n",
            "Epoch 43/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0353 - val_accuracy: 0.9728 - val_loss: 0.0971\n",
            "Epoch 44/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9926 - loss: 0.0304 - val_accuracy: 0.9747 - val_loss: 0.0933\n",
            "Epoch 45/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9931 - loss: 0.0285 - val_accuracy: 0.9730 - val_loss: 0.0976\n",
            "Epoch 46/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9929 - loss: 0.0294 - val_accuracy: 0.9737 - val_loss: 0.0975\n",
            "Epoch 47/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9941 - loss: 0.0271 - val_accuracy: 0.9736 - val_loss: 0.0951\n",
            "Epoch 48/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0268 - val_accuracy: 0.9731 - val_loss: 0.0952\n",
            "Epoch 49/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9954 - loss: 0.0238 - val_accuracy: 0.9728 - val_loss: 0.0999\n",
            "Epoch 50/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0248 - val_accuracy: 0.9740 - val_loss: 0.0949\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1c18506500>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "JP9VWZ2xNYD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = base_model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cEWNVGXwFgj8",
        "outputId": "66357452-f956-4092-a178-591e3b0f9393"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9717 - loss: 0.0939\n",
            "Test Loss: 0.08086122572422028\n",
            "Test Accuracy: 0.9753999710083008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see we have a higher accuracy in training than test accuracy (or even validation!)\n",
        "\n",
        "What's the meaning?\n",
        "\n",
        "OVERFITTING!!!\n",
        "\n",
        "Yes, our model is now overfitted. now we will use different method to address this problem."
      ],
      "metadata": {
        "id": "aZBNAHsOKIzX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regularization"
      ],
      "metadata": {
        "id": "YrrB4VUIKnL_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L2 regularization"
      ],
      "metadata": {
        "id": "JgHhnTamv5sh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "L2 regularization, also known as Ridge Regularization, helps prevent overfitting by discouraging the model from relying too heavily on any single feature.\n",
        "\n",
        "During training, the model is encouraged to keep the weights small to reduce overfitting.\n",
        "\n",
        "The L2 regularization in tensorflow takes a parameter calle penalty strength (also regularization factor) wich determines the strength of the regularization."
      ],
      "metadata": {
        "id": "C60lZZRSLP2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing L2 regularization"
      ],
      "metadata": {
        "id": "dPifbWYTMIRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.regularizers import l2"
      ],
      "metadata": {
        "id": "uiob3AUJIjwd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "VXJQkWWfMNKZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005\n",
        "\n",
        "model_with_l2 = tf.keras.models.Sequential()\n",
        "\n",
        "model_with_l2.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED, ), activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model_with_l2.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model_with_l2.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model_with_l2.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "model_with_l2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "IGx84zbLMMS2",
        "outputId": "350c0eb3-4d7e-4157-ffab-b37fb9958efe"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_l2.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Zuuf8FQyMzC8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_l2.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pnlJyboaNPJe",
        "outputId": "8dea31de-d681-41af-f9ca-5556f10081d4"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.5370 - loss: 4.0345 - val_accuracy: 0.8819 - val_loss: 2.6898\n",
            "Epoch 2/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 2.6167 - val_accuracy: 0.9047 - val_loss: 2.3325\n",
            "Epoch 3/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8990 - loss: 2.2852 - val_accuracy: 0.9145 - val_loss: 2.0687\n",
            "Epoch 4/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 2.0272 - val_accuracy: 0.9201 - val_loss: 1.8503\n",
            "Epoch 5/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 1.8119 - val_accuracy: 0.9237 - val_loss: 1.6651\n",
            "Epoch 6/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 1.6319 - val_accuracy: 0.9268 - val_loss: 1.5066\n",
            "Epoch 7/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9240 - loss: 1.4849 - val_accuracy: 0.9289 - val_loss: 1.3758\n",
            "Epoch 8/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9275 - loss: 1.3500 - val_accuracy: 0.9308 - val_loss: 1.2569\n",
            "Epoch 9/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9293 - loss: 1.2417 - val_accuracy: 0.9323 - val_loss: 1.1570\n",
            "Epoch 10/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9312 - loss: 1.1416 - val_accuracy: 0.9331 - val_loss: 1.0803\n",
            "Epoch 11/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 1.0598 - val_accuracy: 0.9366 - val_loss: 1.0002\n",
            "Epoch 12/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.9920 - val_accuracy: 0.9373 - val_loss: 0.9375\n",
            "Epoch 13/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.9297 - val_accuracy: 0.9403 - val_loss: 0.8822\n",
            "Epoch 14/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.8738 - val_accuracy: 0.9411 - val_loss: 0.8359\n",
            "Epoch 15/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.8282 - val_accuracy: 0.9427 - val_loss: 0.7949\n",
            "Epoch 16/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.7888 - val_accuracy: 0.9421 - val_loss: 0.7604\n",
            "Epoch 17/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9409 - loss: 0.7593 - val_accuracy: 0.9448 - val_loss: 0.7290\n",
            "Epoch 18/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.7292 - val_accuracy: 0.9444 - val_loss: 0.7025\n",
            "Epoch 19/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9424 - loss: 0.7007 - val_accuracy: 0.9461 - val_loss: 0.6786\n",
            "Epoch 20/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9455 - loss: 0.6733 - val_accuracy: 0.9472 - val_loss: 0.6592\n",
            "Epoch 21/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9426 - loss: 0.6590 - val_accuracy: 0.9459 - val_loss: 0.6435\n",
            "Epoch 22/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9451 - loss: 0.6416 - val_accuracy: 0.9473 - val_loss: 0.6260\n",
            "Epoch 23/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9454 - loss: 0.6260 - val_accuracy: 0.9487 - val_loss: 0.6126\n",
            "Epoch 24/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9447 - loss: 0.6140 - val_accuracy: 0.9484 - val_loss: 0.6027\n",
            "Epoch 25/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9491 - loss: 0.5974 - val_accuracy: 0.9492 - val_loss: 0.5925\n",
            "Epoch 26/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.5879 - val_accuracy: 0.9495 - val_loss: 0.5831\n",
            "Epoch 27/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.5799 - val_accuracy: 0.9505 - val_loss: 0.5752\n",
            "Epoch 28/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9487 - loss: 0.5737 - val_accuracy: 0.9503 - val_loss: 0.5678\n",
            "Epoch 29/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.5672 - val_accuracy: 0.9503 - val_loss: 0.5638\n",
            "Epoch 30/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9496 - loss: 0.5591 - val_accuracy: 0.9512 - val_loss: 0.5574\n",
            "Epoch 31/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9494 - loss: 0.5566 - val_accuracy: 0.9499 - val_loss: 0.5556\n",
            "Epoch 32/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9504 - loss: 0.5539 - val_accuracy: 0.9507 - val_loss: 0.5490\n",
            "Epoch 33/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9512 - loss: 0.5465 - val_accuracy: 0.9519 - val_loss: 0.5447\n",
            "Epoch 34/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.5439 - val_accuracy: 0.9513 - val_loss: 0.5429\n",
            "Epoch 35/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9519 - loss: 0.5417 - val_accuracy: 0.9517 - val_loss: 0.5392\n",
            "Epoch 36/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9508 - loss: 0.5389 - val_accuracy: 0.9523 - val_loss: 0.5365\n",
            "Epoch 37/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.5335 - val_accuracy: 0.9533 - val_loss: 0.5340\n",
            "Epoch 38/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9535 - loss: 0.5306 - val_accuracy: 0.9537 - val_loss: 0.5314\n",
            "Epoch 39/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9512 - loss: 0.5336 - val_accuracy: 0.9535 - val_loss: 0.5290\n",
            "Epoch 40/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9535 - loss: 0.5263 - val_accuracy: 0.9529 - val_loss: 0.5279\n",
            "Epoch 41/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9528 - loss: 0.5268 - val_accuracy: 0.9539 - val_loss: 0.5252\n",
            "Epoch 42/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9530 - loss: 0.5272 - val_accuracy: 0.9543 - val_loss: 0.5242\n",
            "Epoch 43/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9533 - loss: 0.5254 - val_accuracy: 0.9552 - val_loss: 0.5228\n",
            "Epoch 44/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.5213 - val_accuracy: 0.9542 - val_loss: 0.5237\n",
            "Epoch 45/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9545 - loss: 0.5215 - val_accuracy: 0.9545 - val_loss: 0.5222\n",
            "Epoch 46/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9552 - loss: 0.5163 - val_accuracy: 0.9560 - val_loss: 0.5207\n",
            "Epoch 47/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9544 - loss: 0.5205 - val_accuracy: 0.9534 - val_loss: 0.5216\n",
            "Epoch 48/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9543 - loss: 0.5200 - val_accuracy: 0.9558 - val_loss: 0.5178\n",
            "Epoch 49/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9559 - loss: 0.5177 - val_accuracy: 0.9550 - val_loss: 0.5176\n",
            "Epoch 50/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9555 - loss: 0.5185 - val_accuracy: 0.9566 - val_loss: 0.5171\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1c003b3af0>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "wvlfxxjDNeJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model_with_l2.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0624_LW0NTuV",
        "outputId": "d204484b-bc61-472c-83ff-c06f347ac6de"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9467 - loss: 0.5414\n",
            "Test Loss: 0.5152761340141296\n",
            "Test Accuracy: 0.9546999931335449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the training accuracy decreased around 95% (validation accuracy is around 95%) and the test accuracy is also around 95%!\n",
        "\n",
        "This means that the L2 regularization prevented the model from overfitting."
      ],
      "metadata": {
        "id": "GQ5aF1_jO9QA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dropout"
      ],
      "metadata": {
        "id": "WQFemfeIwAyL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Dropout__ is a regularization technique used in deep learning to prevent overfitting. It works by randomly “dropping out” (setting to zero) a fraction of neurons during training, effectively creating a thinner, temporary version of the neural network. This forces the model to learn more robust and generalized features rather than relying too heavily on specific neurons."
      ],
      "metadata": {
        "id": "X5FYdbymwDR9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "FyYVNSUiwd1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005\n",
        "DROPOUT_RATE = .2\n",
        "\n",
        "model_with_l2_and_dropout = tf.keras.models.Sequential()\n",
        "\n",
        "model_with_l2_and_dropout.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED, ), activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model_with_l2_and_dropout.add(keras.layers.Dropout(DROPOUT_RATE))\n",
        "\n",
        "model_with_l2_and_dropout.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model_with_l2_and_dropout.add(keras.layers.Dropout(DROPOUT_RATE))\n",
        "\n",
        "model_with_l2_and_dropout.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model_with_l2_and_dropout.add(keras.layers.Dropout(DROPOUT_RATE))\n",
        "\n",
        "model_with_l2_and_dropout.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "model_with_l2_and_dropout.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "srsRdosnwdmN",
        "outputId": "21e91236-d1d8-4a92-a1a3-0cc4492e4686"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_4\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_4\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "gUWRKA0lynHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_l2_and_dropout.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TOUAVhc_ypha"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model\n"
      ],
      "metadata": {
        "id": "PEfBXD5eyrHu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_l2_and_dropout.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "RSqyi2KFyxDl",
        "outputId": "2f634222-73df-449e-c8de-f083e2cafa34"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.3523 - loss: 4.3294 - val_accuracy: 0.8508 - val_loss: 2.8063\n",
            "Epoch 2/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7674 - loss: 2.8968 - val_accuracy: 0.8922 - val_loss: 2.3591\n",
            "Epoch 3/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8304 - loss: 2.4594 - val_accuracy: 0.9033 - val_loss: 2.0792\n",
            "Epoch 4/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8567 - loss: 2.1655 - val_accuracy: 0.9133 - val_loss: 1.8505\n",
            "Epoch 5/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8693 - loss: 1.9419 - val_accuracy: 0.9185 - val_loss: 1.6626\n",
            "Epoch 6/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 1.7481 - val_accuracy: 0.9222 - val_loss: 1.5032\n",
            "Epoch 7/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8900 - loss: 1.5849 - val_accuracy: 0.9253 - val_loss: 1.3656\n",
            "Epoch 8/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8955 - loss: 1.4412 - val_accuracy: 0.9302 - val_loss: 1.2474\n",
            "Epoch 9/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 1.3319 - val_accuracy: 0.9332 - val_loss: 1.1474\n",
            "Epoch 10/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 1.2228 - val_accuracy: 0.9346 - val_loss: 1.0621\n",
            "Epoch 11/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 1.1439 - val_accuracy: 0.9366 - val_loss: 0.9898\n",
            "Epoch 12/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 1.0665 - val_accuracy: 0.9377 - val_loss: 0.9265\n",
            "Epoch 13/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 1.0117 - val_accuracy: 0.9402 - val_loss: 0.8729\n",
            "Epoch 14/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.9496 - val_accuracy: 0.9420 - val_loss: 0.8253\n",
            "Epoch 15/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.9050 - val_accuracy: 0.9436 - val_loss: 0.7846\n",
            "Epoch 16/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.8642 - val_accuracy: 0.9438 - val_loss: 0.7521\n",
            "Epoch 17/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.8246 - val_accuracy: 0.9463 - val_loss: 0.7204\n",
            "Epoch 18/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9212 - loss: 0.7886 - val_accuracy: 0.9468 - val_loss: 0.6944\n",
            "Epoch 19/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.7678 - val_accuracy: 0.9466 - val_loss: 0.6740\n",
            "Epoch 20/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.7440 - val_accuracy: 0.9480 - val_loss: 0.6556\n",
            "Epoch 21/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9255 - loss: 0.7306 - val_accuracy: 0.9488 - val_loss: 0.6369\n",
            "Epoch 22/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.7115 - val_accuracy: 0.9488 - val_loss: 0.6239\n",
            "Epoch 23/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.6969 - val_accuracy: 0.9498 - val_loss: 0.6119\n",
            "Epoch 24/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9253 - loss: 0.6825 - val_accuracy: 0.9513 - val_loss: 0.6000\n",
            "Epoch 25/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9265 - loss: 0.6721 - val_accuracy: 0.9503 - val_loss: 0.5902\n",
            "Epoch 26/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9281 - loss: 0.6639 - val_accuracy: 0.9508 - val_loss: 0.5827\n",
            "Epoch 27/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9313 - loss: 0.6540 - val_accuracy: 0.9520 - val_loss: 0.5743\n",
            "Epoch 28/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9276 - loss: 0.6486 - val_accuracy: 0.9514 - val_loss: 0.5708\n",
            "Epoch 29/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.6348 - val_accuracy: 0.9524 - val_loss: 0.5625\n",
            "Epoch 30/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9327 - loss: 0.6306 - val_accuracy: 0.9523 - val_loss: 0.5585\n",
            "Epoch 31/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9316 - loss: 0.6270 - val_accuracy: 0.9526 - val_loss: 0.5540\n",
            "Epoch 32/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.6211 - val_accuracy: 0.9539 - val_loss: 0.5501\n",
            "Epoch 33/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.6232 - val_accuracy: 0.9527 - val_loss: 0.5469\n",
            "Epoch 34/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.6081 - val_accuracy: 0.9524 - val_loss: 0.5450\n",
            "Epoch 35/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9342 - loss: 0.6084 - val_accuracy: 0.9544 - val_loss: 0.5395\n",
            "Epoch 36/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.6069 - val_accuracy: 0.9549 - val_loss: 0.5382\n",
            "Epoch 37/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.6031 - val_accuracy: 0.9553 - val_loss: 0.5355\n",
            "Epoch 38/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.6027 - val_accuracy: 0.9542 - val_loss: 0.5357\n",
            "Epoch 39/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9381 - loss: 0.5929 - val_accuracy: 0.9557 - val_loss: 0.5334\n",
            "Epoch 40/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9351 - loss: 0.5983 - val_accuracy: 0.9553 - val_loss: 0.5312\n",
            "Epoch 41/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9363 - loss: 0.5981 - val_accuracy: 0.9558 - val_loss: 0.5309\n",
            "Epoch 42/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.5950 - val_accuracy: 0.9556 - val_loss: 0.5278\n",
            "Epoch 43/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.5918 - val_accuracy: 0.9553 - val_loss: 0.5273\n",
            "Epoch 44/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.5893 - val_accuracy: 0.9547 - val_loss: 0.5263\n",
            "Epoch 45/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9387 - loss: 0.5826 - val_accuracy: 0.9567 - val_loss: 0.5251\n",
            "Epoch 46/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.5880 - val_accuracy: 0.9550 - val_loss: 0.5244\n",
            "Epoch 47/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.5797 - val_accuracy: 0.9567 - val_loss: 0.5238\n",
            "Epoch 48/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9385 - loss: 0.5836 - val_accuracy: 0.9563 - val_loss: 0.5220\n",
            "Epoch 49/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.5868 - val_accuracy: 0.9563 - val_loss: 0.5219\n",
            "Epoch 50/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9399 - loss: 0.5781 - val_accuracy: 0.9560 - val_loss: 0.5211\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1c234a5630>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the moedel"
      ],
      "metadata": {
        "id": "khPImXcGy0mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model_with_l2_and_dropout.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lrGmmzNWy3ge",
        "outputId": "acf044c6-1517-4294-f578-55c05ddcba40"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9480 - loss: 0.5475\n",
            "Test Loss: 0.520433783531189\n",
            "Test Accuracy: 0.9570000171661377\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we used both regularization (L2 and Dropout) the accuracy of the model decreased to 94% (accuracy of the validatino set 95%) and the test acccuracy is now 96%. This also mean that the model is not overfit."
      ],
      "metadata": {
        "id": "TToJxEN02aE8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Optimization Algorithms"
      ],
      "metadata": {
        "id": "xCb4JEZBPRPM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimization algorithms in deep learning are techniques used to minimize the loss function by updating the weights of the model during training.\n",
        "\n",
        "1. __Stochastic Gradient Descent (SGD):__ Updates weights by moving in the direction of the negative gradient of the loss function with respect to the weights.\n",
        "\n",
        "2. __Adam (Adaptive Moment Estimation):__ Combines the advantages of Momentum and RMSprop by using adaptive learning rates and keeping track of both first and second moments of the gradients.\n",
        "\n",
        "3. __RMSprop (Root Mean Square Propagation):__ Adjusts the learning rate for each parameter individually, scaling it inversely proportional to the square root of the recent average of gradients.\n",
        "\n",
        "Each optimizer has its strengths and weaknesses, and the choice often depends on the problem, model architecture, and dataset."
      ],
      "metadata": {
        "id": "te6RSCacPg9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "NSpa0u-7QaRV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005\n",
        "DROPOUT_RATE = .4\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED, ), activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_1\"))\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_2\"))\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_3\"))\n",
        "\n",
        "model.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "1KQ35bvqOQK8",
        "outputId": "16324e0f-7b77-4568-87ca-983fc9e56d7a"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model with different optimaizers (SGD, adam, RMSProp)"
      ],
      "metadata": {
        "id": "pXizeUJQQc8_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(We already saw the model with \"SGD\")"
      ],
      "metadata": {
        "id": "SRPFb0xmQv4s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## adam"
      ],
      "metadata": {
        "id": "YIZSujOxSiup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "6F-bnDmmQWDg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "pmNXW1dzQ4_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YZmKJ1YrQ4VL",
        "outputId": "ba4b0f28-f9aa-46f6-9b84-b2786133d529"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.6525 - loss: 2.2443 - val_accuracy: 0.9277 - val_loss: 0.7300\n",
            "Epoch 2/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 2ms/step - accuracy: 0.8896 - loss: 0.8374 - val_accuracy: 0.9383 - val_loss: 0.6415\n",
            "Epoch 3/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8989 - loss: 0.7691 - val_accuracy: 0.9373 - val_loss: 0.6194\n",
            "Epoch 4/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.7504 - val_accuracy: 0.9433 - val_loss: 0.6080\n",
            "Epoch 5/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.7325 - val_accuracy: 0.9429 - val_loss: 0.5998\n",
            "Epoch 6/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.7333 - val_accuracy: 0.9452 - val_loss: 0.5954\n",
            "Epoch 7/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.7305 - val_accuracy: 0.9393 - val_loss: 0.6058\n",
            "Epoch 8/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.7193 - val_accuracy: 0.9423 - val_loss: 0.6053\n",
            "Epoch 9/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.7247 - val_accuracy: 0.9427 - val_loss: 0.6031\n",
            "Epoch 10/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.7237 - val_accuracy: 0.9408 - val_loss: 0.6037\n",
            "Epoch 11/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.7201 - val_accuracy: 0.9411 - val_loss: 0.6042\n",
            "Epoch 12/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.7192 - val_accuracy: 0.9430 - val_loss: 0.5982\n",
            "Epoch 13/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.7222 - val_accuracy: 0.9466 - val_loss: 0.5836\n",
            "Epoch 14/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.7209 - val_accuracy: 0.9457 - val_loss: 0.5881\n",
            "Epoch 15/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.7154 - val_accuracy: 0.9424 - val_loss: 0.5938\n",
            "Epoch 16/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.7215 - val_accuracy: 0.9414 - val_loss: 0.5957\n",
            "Epoch 17/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.7286 - val_accuracy: 0.9457 - val_loss: 0.5867\n",
            "Epoch 18/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.7205 - val_accuracy: 0.9463 - val_loss: 0.5863\n",
            "Epoch 19/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.7162 - val_accuracy: 0.9464 - val_loss: 0.5844\n",
            "Epoch 20/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.7162 - val_accuracy: 0.9433 - val_loss: 0.5917\n",
            "Epoch 21/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.7150 - val_accuracy: 0.9474 - val_loss: 0.5891\n",
            "Epoch 22/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.7158 - val_accuracy: 0.9427 - val_loss: 0.5869\n",
            "Epoch 23/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.7164 - val_accuracy: 0.9442 - val_loss: 0.5899\n",
            "Epoch 24/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.7231 - val_accuracy: 0.9476 - val_loss: 0.5830\n",
            "Epoch 25/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.7122 - val_accuracy: 0.9438 - val_loss: 0.5894\n",
            "Epoch 26/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.7224 - val_accuracy: 0.9487 - val_loss: 0.5784\n",
            "Epoch 27/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.7079 - val_accuracy: 0.9382 - val_loss: 0.6046\n",
            "Epoch 28/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.7159 - val_accuracy: 0.9393 - val_loss: 0.5933\n",
            "Epoch 29/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.7082 - val_accuracy: 0.9457 - val_loss: 0.5826\n",
            "Epoch 30/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.7043 - val_accuracy: 0.9464 - val_loss: 0.5824\n",
            "Epoch 31/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.7077 - val_accuracy: 0.9416 - val_loss: 0.6039\n",
            "Epoch 32/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.7115 - val_accuracy: 0.9482 - val_loss: 0.5766\n",
            "Epoch 33/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.7017 - val_accuracy: 0.9432 - val_loss: 0.5901\n",
            "Epoch 34/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.7100 - val_accuracy: 0.9409 - val_loss: 0.5949\n",
            "Epoch 35/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.7158 - val_accuracy: 0.9458 - val_loss: 0.5868\n",
            "Epoch 36/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.7173 - val_accuracy: 0.9474 - val_loss: 0.5729\n",
            "Epoch 37/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.7184 - val_accuracy: 0.9478 - val_loss: 0.5743\n",
            "Epoch 38/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.7082 - val_accuracy: 0.9471 - val_loss: 0.5809\n",
            "Epoch 39/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.7123 - val_accuracy: 0.9443 - val_loss: 0.5824\n",
            "Epoch 40/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.7149 - val_accuracy: 0.9442 - val_loss: 0.5878\n",
            "Epoch 41/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.7089 - val_accuracy: 0.9383 - val_loss: 0.5993\n",
            "Epoch 42/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.7074 - val_accuracy: 0.9462 - val_loss: 0.5790\n",
            "Epoch 43/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.7067 - val_accuracy: 0.9433 - val_loss: 0.5899\n",
            "Epoch 44/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.7143 - val_accuracy: 0.9464 - val_loss: 0.5770\n",
            "Epoch 45/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.7053 - val_accuracy: 0.9464 - val_loss: 0.5836\n",
            "Epoch 46/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.7089 - val_accuracy: 0.9397 - val_loss: 0.5995\n",
            "Epoch 47/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.7024 - val_accuracy: 0.9377 - val_loss: 0.6084\n",
            "Epoch 48/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.7133 - val_accuracy: 0.9468 - val_loss: 0.5889\n",
            "Epoch 49/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.7183 - val_accuracy: 0.9452 - val_loss: 0.5865\n",
            "Epoch 50/50\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.7060 - val_accuracy: 0.9463 - val_loss: 0.5837\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1bec3b2da0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "hlF5Fw8cRD6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_Z4cwW32Q_-t",
        "outputId": "ac614308-5761-4f1e-8ec3-aa885ff19b45"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.6177\n",
            "Test Loss: 0.5879926681518555\n",
            "Test Accuracy: 0.942300021648407\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it shown, the model accuracy won't increase from a certain point, so I reduice the number of epochs to 20."
      ],
      "metadata": {
        "id": "cwE89eUV30Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS= 20"
      ],
      "metadata": {
        "id": "M3YamanA4AaN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RMSProp"
      ],
      "metadata": {
        "id": "d3-fb8whSokU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "hvKYIi9uTIhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005\n",
        "DROPOUT_RATE = .4\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED, ), activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_1\"))\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_2\"))\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, activation=\"relu\", kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_3\"))\n",
        "\n",
        "model.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "HzQz5wSWTIE8",
        "outputId": "7062741c-26a3-4ea2-b0d0-242a42656038"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,794\u001b[0m (526.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,794</span> (526.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "ygY8n9Y4SveU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"RMSprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "Tn0Pu_YOSWde"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "pSFr1LhSSybZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_WGaqBwNSuel",
        "outputId": "d10b1b78-08af-4ad5-da6a-5c6c6097ed3f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6735 - loss: 2.1636 - val_accuracy: 0.9258 - val_loss: 0.7110\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8835 - loss: 0.8283 - val_accuracy: 0.9352 - val_loss: 0.6276\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.7708 - val_accuracy: 0.9310 - val_loss: 0.6280\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8985 - loss: 0.7470 - val_accuracy: 0.9380 - val_loss: 0.6043\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8991 - loss: 0.7431 - val_accuracy: 0.9331 - val_loss: 0.6055\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.7360 - val_accuracy: 0.9361 - val_loss: 0.6080\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8992 - loss: 0.7400 - val_accuracy: 0.9263 - val_loss: 0.6278\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.7278 - val_accuracy: 0.9392 - val_loss: 0.5917\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9023 - loss: 0.7252 - val_accuracy: 0.9428 - val_loss: 0.5864\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.7214 - val_accuracy: 0.9412 - val_loss: 0.5919\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.7223 - val_accuracy: 0.9400 - val_loss: 0.5901\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9024 - loss: 0.7250 - val_accuracy: 0.9396 - val_loss: 0.5935\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9011 - loss: 0.7191 - val_accuracy: 0.9397 - val_loss: 0.5843\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.7253 - val_accuracy: 0.9389 - val_loss: 0.5956\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.7210 - val_accuracy: 0.9384 - val_loss: 0.5923\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.7195 - val_accuracy: 0.9359 - val_loss: 0.5975\n",
            "Epoch 17/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9048 - loss: 0.7135 - val_accuracy: 0.9400 - val_loss: 0.5855\n",
            "Epoch 18/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.7177 - val_accuracy: 0.9426 - val_loss: 0.5849\n",
            "Epoch 19/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9031 - loss: 0.7154 - val_accuracy: 0.9400 - val_loss: 0.5856\n",
            "Epoch 20/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.7156 - val_accuracy: 0.9335 - val_loss: 0.6011\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1bc65b4fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "B4LL1XIrTVKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wWF8RuvUS5xU",
        "outputId": "3cd7382f-ea2c-4470-992f-3fe5ffc2a12a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.6430\n",
            "Test Loss: 0.6026926636695862\n",
            "Test Accuracy: 0.9325000047683716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is obvious, is the fact that now the model converge much faster!"
      ],
      "metadata": {
        "id": "mADSvc5lT9wD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Batch Normalization"
      ],
      "metadata": {
        "id": "rcv3igW6ULqf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Normalization (BatchNorm) is a technique to improve the training of deep neural networks by normalizing the input of each layer. It helps stabilize and accelerate the learning process by reducing internal covariate shift, which occurs when the distribution of inputs to a layer changes during training."
      ],
      "metadata": {
        "id": "5mDD1xK2Uc2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing batch normalization"
      ],
      "metadata": {
        "id": "B9S3MK8TUmnU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "co64n6wrUFR_"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "xiSOQ5T6UqmG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* __Batch Normalization__ is typically applied before the activation function because it normalizes the activations of the previous layer, which helps stabilize training and accelerates convergence.\n",
        "\n",
        "*\t__Dropout is applied__ after the activation function because it works by randomly deactivating neurons during training, which helps with generalization by preventing overfitting."
      ],
      "metadata": {
        "id": "aZhmJ6xe0m4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005 # L2 regularization factor\n",
        "DROPOUT_RATE = 0.4  # Dropout rate\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# First dense layer with L2 regularization\n",
        "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED,), kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_1\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_1\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_1\"))  # Apply Dropout\n",
        "\n",
        "# Second dense layer with L2 regularization\n",
        "model.add(keras.layers.Dense(N_HIDDEN, kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_2\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_2\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_2\"))  # Apply Dropout\n",
        "\n",
        "# Third dense layer with L2 regularization\n",
        "model.add(keras.layers.Dense(N_HIDDEN, kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_3\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_3\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_3\"))  # Apply Dropout\n",
        "\n",
        "# Output layer with softmax activation for classification\n",
        "model.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "# Model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "cESSD5KOUqMe",
        "outputId": "915f51ca-e08f-4e4d-d100-724962ffa66b"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_7\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_7\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m136,330\u001b[0m (532.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,330</span> (532.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,562\u001b[0m (529.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,562</span> (529.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "ObdRx0H_Vcsl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "2lQMmim9VNZI"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Trainig the model"
      ],
      "metadata": {
        "id": "5EnLXz4_V-hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FmMKHxM5V-ED",
        "outputId": "eab34017-46d8-4d0b-f57a-67d180a95af6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.6648 - loss: 2.5977 - val_accuracy: 0.9321 - val_loss: 0.7021\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8853 - loss: 0.7744 - val_accuracy: 0.9500 - val_loss: 0.4454\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9018 - loss: 0.5951 - val_accuracy: 0.9521 - val_loss: 0.4061\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9073 - loss: 0.5572 - val_accuracy: 0.9608 - val_loss: 0.3739\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.5384 - val_accuracy: 0.9571 - val_loss: 0.3785\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.5299 - val_accuracy: 0.9498 - val_loss: 0.3956\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.5228 - val_accuracy: 0.9562 - val_loss: 0.3774\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.5259 - val_accuracy: 0.9546 - val_loss: 0.3834\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9151 - loss: 0.5235 - val_accuracy: 0.9582 - val_loss: 0.3752\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.5176 - val_accuracy: 0.9549 - val_loss: 0.3841\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.5203 - val_accuracy: 0.9573 - val_loss: 0.3776\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.5106 - val_accuracy: 0.9592 - val_loss: 0.3687\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.5197 - val_accuracy: 0.9634 - val_loss: 0.3612\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.5195 - val_accuracy: 0.9584 - val_loss: 0.3817\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.5151 - val_accuracy: 0.9514 - val_loss: 0.3910\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9214 - loss: 0.5042 - val_accuracy: 0.9542 - val_loss: 0.3869\n",
            "Epoch 17/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9221 - loss: 0.5065 - val_accuracy: 0.9597 - val_loss: 0.3685\n",
            "Epoch 18/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.5159 - val_accuracy: 0.9578 - val_loss: 0.3769\n",
            "Epoch 19/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.5058 - val_accuracy: 0.9587 - val_loss: 0.3754\n",
            "Epoch 20/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9209 - loss: 0.5077 - val_accuracy: 0.9534 - val_loss: 0.3854\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1b9a1e1750>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "z1YMgR0wWDWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "ncpZio3GWCdp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "6da52fd5-99a4-457b-f41a-871448f68838"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9451 - loss: 0.4109\n",
            "Test Loss: 0.3872843086719513\n",
            "Test Accuracy: 0.9524999856948853\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning Rate Schedulers"
      ],
      "metadata": {
        "id": "kQXn2KOs6L57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Learning rate schedulers adjust the learning rate during training to help improve convergence and model performance. Common strategies include __step decay__, __exponential decay__, and others."
      ],
      "metadata": {
        "id": "b2z0jjWB6O_0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step Decay"
      ],
      "metadata": {
        "id": "UsKoqv986obO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_lr = 0.1\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=initial_lr,\n",
        "    decay_steps=1000,  # Step size\n",
        "    decay_rate=0.5,    # Decay factor\n",
        "    staircase=True     # Enable step decay\n",
        ")\n",
        "\n",
        "step_decay_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "metadata": {
        "id": "CdEMO1PMadu6"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "bZLDvaJl7ZFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005\n",
        "DROPOUT_RATE = 0.4\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED,), kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_1\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_1\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_1\"))  # Apply Dropout\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_2\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_2\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_2\"))  # Apply Dropout\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_3\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_3\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_3\"))  # Apply Dropout\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "1BNbgtSH7bUB",
        "outputId": "333d63e8-b6c9-4c32-966b-4c32d596d466"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m136,330\u001b[0m (532.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,330</span> (532.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,562\u001b[0m (529.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,562</span> (529.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "z7LU-tTj83d0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=step_decay_optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "MAYogqsy8rXQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training the model"
      ],
      "metadata": {
        "id": "J3AoUQMm8_45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "V94Nr69a82rJ",
        "outputId": "7bf2602a-16fb-41e1-8cea-062f6016ac08"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.4405 - loss: 6.4006 - val_accuracy: 0.4033 - val_loss: 5.1519\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4466 - loss: 4.5976 - val_accuracy: 0.6060 - val_loss: 3.5648\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5147 - loss: 3.6933 - val_accuracy: 0.6712 - val_loss: 2.5796\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5983 - loss: 2.8023 - val_accuracy: 0.4633 - val_loss: 3.1654\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.6705 - loss: 2.1073 - val_accuracy: 0.7339 - val_loss: 1.8402\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7121 - loss: 1.8847 - val_accuracy: 0.8357 - val_loss: 1.2370\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7637 - loss: 1.4763 - val_accuracy: 0.9136 - val_loss: 0.8006\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8127 - loss: 1.1156 - val_accuracy: 0.8862 - val_loss: 0.8365\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8303 - loss: 0.9609 - val_accuracy: 0.9283 - val_loss: 0.5500\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8504 - loss: 0.8348 - val_accuracy: 0.9536 - val_loss: 0.4119\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.6805 - val_accuracy: 0.9612 - val_loss: 0.3484\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8888 - loss: 0.5966 - val_accuracy: 0.9629 - val_loss: 0.3098\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.5534 - val_accuracy: 0.9670 - val_loss: 0.2756\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.5046 - val_accuracy: 0.9698 - val_loss: 0.2566\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.4939 - val_accuracy: 0.9707 - val_loss: 0.2460\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.4741 - val_accuracy: 0.9711 - val_loss: 0.2413\n",
            "Epoch 17/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.4669 - val_accuracy: 0.9724 - val_loss: 0.2362\n",
            "Epoch 18/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.4604 - val_accuracy: 0.9722 - val_loss: 0.2345\n",
            "Epoch 19/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.4520 - val_accuracy: 0.9721 - val_loss: 0.2327\n",
            "Epoch 20/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.4447 - val_accuracy: 0.9727 - val_loss: 0.2318\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1b9021b010>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "ZnGb8GNm9qW1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "93BgK-Q99BXk",
        "outputId": "ec5a03fd-1b8b-4590-e6c2-89c7ef5348b0"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9674 - loss: 0.2446\n",
            "Test Loss: 0.22834713757038116\n",
            "Test Accuracy: 0.9725000262260437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exponential Decay"
      ],
      "metadata": {
        "id": "ce5V5PmU-D5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_lr = 0.1\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=initial_lr,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.96,  # Exponential decay rate\n",
        "    staircase=False   # Continuous decay\n",
        ")\n",
        "\n",
        "exponential_decay_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
      ],
      "metadata": {
        "id": "1KR2afFV93wj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the model"
      ],
      "metadata": {
        "id": "9wexyAN5-Ssh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L2_REG_FAC = .005\n",
        "DROPOUT_RATE = 0.4\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, input_shape=(RESHAPED,), kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_1\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_1\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_1\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_1\"))  # Apply Dropout\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_2\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_2\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_2\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_2\"))  # Apply Dropout\n",
        "\n",
        "model.add(keras.layers.Dense(N_HIDDEN, kernel_regularizer=l2(L2_REG_FAC), name=\"Dense_Layer_3\"))\n",
        "model.add(BatchNormalization(name=\"Batch_Normalization_Layer_3\"))  # Apply Batch Normalization\n",
        "model.add(keras.layers.Activation(\"relu\", name=\"Relu_activation_funtion_3\"))  # ReLU activation function\n",
        "model.add(keras.layers.Dropout(DROPOUT_RATE, name=\"Dropout_Layer_3\"))  # Apply Dropout\n",
        "\n",
        "\n",
        "model.add(keras.layers.Dense(NB_CLASSES, activation=\"softmax\", kernel_regularizer=l2(L2_REG_FAC), name=\"Output_Layer\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "UJBAJIi4-Oko",
        "outputId": "3c9a785d-7201-4177-9900-b5f6d21d6dee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_1          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_1            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_2          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_2            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_3          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_3            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mActivation\u001b[0m)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ Dense_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_1          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_1            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_2          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_2            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dense_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Batch_Normalization_Layer_3          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Relu_activation_funtion_3            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)                         │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Dropout_Layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ Output_Layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m136,330\u001b[0m (532.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">136,330</span> (532.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m135,562\u001b[0m (529.54 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,562</span> (529.54 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compiling the model"
      ],
      "metadata": {
        "id": "CyIIdasR-WBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=exponential_decay_optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "mXTlHiyk-VMf"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### training the model"
      ],
      "metadata": {
        "id": "KwYZ-UvJ-eVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=VERBOSE, validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wKEgl5Eb-fxN",
        "outputId": "631cc6cd-d929-4006-9a58-790f862187db"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.4460 - loss: 6.4333 - val_accuracy: 0.3784 - val_loss: 4.9036\n",
            "Epoch 2/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.4254 - loss: 5.0700 - val_accuracy: 0.4556 - val_loss: 4.7287\n",
            "Epoch 3/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4178 - loss: 4.9685 - val_accuracy: 0.4683 - val_loss: 4.8768\n",
            "Epoch 4/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.4365 - loss: 4.9824 - val_accuracy: 0.4499 - val_loss: 5.0829\n",
            "Epoch 5/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4341 - loss: 4.7935 - val_accuracy: 0.4367 - val_loss: 4.8969\n",
            "Epoch 6/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4285 - loss: 4.7845 - val_accuracy: 0.4285 - val_loss: 4.6988\n",
            "Epoch 7/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4289 - loss: 4.7035 - val_accuracy: 0.3751 - val_loss: 5.1100\n",
            "Epoch 8/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4386 - loss: 4.6071 - val_accuracy: 0.5617 - val_loss: 4.3466\n",
            "Epoch 9/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4430 - loss: 4.6447 - val_accuracy: 0.5155 - val_loss: 4.7268\n",
            "Epoch 10/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4550 - loss: 4.5627 - val_accuracy: 0.5153 - val_loss: 3.7686\n",
            "Epoch 11/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4616 - loss: 4.4661 - val_accuracy: 0.4019 - val_loss: 4.0156\n",
            "Epoch 12/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4583 - loss: 4.3911 - val_accuracy: 0.4408 - val_loss: 8.3544\n",
            "Epoch 13/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4617 - loss: 4.3784 - val_accuracy: 0.4409 - val_loss: 4.6563\n",
            "Epoch 14/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.4794 - loss: 4.2763 - val_accuracy: 0.4207 - val_loss: 4.3571\n",
            "Epoch 15/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.4738 - loss: 4.2272 - val_accuracy: 0.5842 - val_loss: 3.5465\n",
            "Epoch 16/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.4839 - loss: 4.1792 - val_accuracy: 0.5305 - val_loss: 4.0845\n",
            "Epoch 17/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4977 - loss: 4.1222 - val_accuracy: 0.4614 - val_loss: 3.9579\n",
            "Epoch 18/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.4878 - loss: 4.0664 - val_accuracy: 0.6217 - val_loss: 3.8266\n",
            "Epoch 19/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5000 - loss: 3.9765 - val_accuracy: 0.5822 - val_loss: 3.8940\n",
            "Epoch 20/20\n",
            "\u001b[1m750/750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.5055 - loss: 3.8960 - val_accuracy: 0.5699 - val_loss: 3.6991\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7c1bec3b10f0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "nq-IN7tN-mzf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Test Loss:\", test_loss)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GIU2zNo3-mFL",
        "outputId": "4aba3099-4a8f-44dc-f392-5eb988adb178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.4470 - loss: 4.0911\n",
            "Test Loss: 4.02934455871582\n",
            "Test Accuracy: 0.46790000796318054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This may not a good idea for this specific task!"
      ],
      "metadata": {
        "id": "CI7FRpC3_tAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "pP6acYel_KZA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameter tuning for a neural network involves finding the optimal combination of hyperparameters that maximizes the model’s performance."
      ],
      "metadata": {
        "id": "eBwix9LL_PeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Keras Tuner library provides an efficient way to perform hyperparameter tuning to achieve the best accuracy. It supports multiple search algorithms, including Random Search, Hyperband, and Bayesian Optimization. Here’s a step-by-step guide to using Keras Tuner effectively."
      ],
      "metadata": {
        "id": "tAoz00BP1X5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Intaling and importing __keras Tuner__ library"
      ],
      "metadata": {
        "id": "trG3vFhe1af3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras-tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "JgL30y8N1kIV",
        "outputId": "edda5225-894d-4136-db0c-e65bc37061ee"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner import HyperModel"
      ],
      "metadata": {
        "id": "ocPjlgfc_Lsi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "03945ec4-6149-4788-fbd9-ee0b7c2ab8e4"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-52-a5609439cedd>:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner import HyperModel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the tuner"
      ],
      "metadata": {
        "id": "wfMday-W2CD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # First Dense Layer\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=hp.Int('units_1', min_value=64, max_value=256, step=64),\n",
        "        kernel_regularizer=l2(hp.Choice('l2_reg_1', values=[0.001, 0.005, 0.01])),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Dropout(hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Second Dense Layer\n",
        "    model.add(keras.layers.Dense(\n",
        "        units=hp.Int('units_2', min_value=64, max_value=256, step=64),\n",
        "        kernel_regularizer=l2(hp.Choice('l2_reg_2', values=[0.001, 0.005, 0.01])),\n",
        "        activation='relu'\n",
        "    ))\n",
        "    model.add(keras.layers.BatchNormalization())\n",
        "    model.add(keras.layers.Dropout(hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))\n",
        "\n",
        "    # Output Layer\n",
        "    model.add(keras.layers.Dense(NB_CLASSES, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer=hp.Choice('optimizer', values=['adam', 'RMSProp', 'SGD']),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "tpHq7vEB1fQ9"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize the tuner"
      ],
      "metadata": {
        "id": "lRZRB4072jf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import BayesianOptimization\n",
        "\n",
        "tuner = BayesianOptimization(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=15,\n",
        "    directory='hyperparam_tuning',\n",
        "    project_name='bayesian_optimization'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TCdudGxb2FAe",
        "outputId": "5455c844-d5ee-47ea-c4a5-efafd982750a"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from hyperparam_tuning/bayesian_optimization/tuner0.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execute the Search"
      ],
      "metadata": {
        "id": "RnFKiA123Y_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=20,\n",
        "    validation_split=0.2,\n",
        "    batch_size=64,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "id": "KKVNuyBK2mWG"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Retrieve the Best Hyperparameters and Building and Training the Model"
      ],
      "metadata": {
        "id": "fPQcdqjd3fq7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best hyperparameters:\")\n",
        "print(best_hps.values)\n",
        "\n",
        "# Build the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Train the best model further if needed\n",
        "history = best_model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=10,\n",
        "    validation_split=0.2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "H4D9zma73iCw",
        "outputId": "7024a66b-4d16-49c4-d293-6800da974dd6"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters:\n",
            "{'units_1': 128, 'l2_reg_1': 0.001, 'dropout_1': 0.2, 'units_2': 128, 'l2_reg_2': 0.005, 'dropout_2': 0.2, 'optimizer': 'SGD'}\n",
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9655 - loss: 0.2688 - val_accuracy: 0.9743 - val_loss: 0.2437\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 3ms/step - accuracy: 0.9648 - loss: 0.2618 - val_accuracy: 0.9722 - val_loss: 0.2387\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9682 - loss: 0.2476 - val_accuracy: 0.9752 - val_loss: 0.2269\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9658 - loss: 0.2417 - val_accuracy: 0.9761 - val_loss: 0.2175\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9700 - loss: 0.2255 - val_accuracy: 0.9750 - val_loss: 0.2134\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9725 - loss: 0.2154 - val_accuracy: 0.9772 - val_loss: 0.2032\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9716 - loss: 0.2092 - val_accuracy: 0.9758 - val_loss: 0.2019\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9722 - loss: 0.2014 - val_accuracy: 0.9763 - val_loss: 0.1972\n",
            "Epoch 9/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9734 - loss: 0.1962 - val_accuracy: 0.9770 - val_loss: 0.1884\n",
            "Epoch 10/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9741 - loss: 0.1891 - val_accuracy: 0.9773 - val_loss: 0.1878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ploting the Result"
      ],
      "metadata": {
        "id": "m5Cao9SJ9WSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "UrZQ_NVb74aK",
        "outputId": "f15615b1-c34a-4e25-b876-91de8baa8b03"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating the model"
      ],
      "metadata": {
        "id": "FrHkD6w09cy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "test_loss, test_acc = best_model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QIdH_9bo9eYe",
        "outputId": "1d67acbc-94c2-4f0f-8f4d-513c7acef769"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.1895\n",
            "Test accuracy: 0.9779000282287598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WE93OuHh9rLd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}